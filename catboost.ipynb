{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from metrics import deviation_metric\n",
    "import catboost as cb\n",
    "from metrics import deviation_metric_one_sample\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0         139937.500000\n1          60410.714286\n2          45164.761264\n3          28805.263158\n4          13222.591362\n              ...      \n275294     25450.669915\n275295     43525.000000\n275296     28727.272727\n275297     79068.245559\n275298     41160.714286\nName: target, Length: 275299, dtype: float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/train_parse3.csv')\n",
    "X_train, X_test = df[df[\"price_type\"] == 0].drop(columns=[\"target\"]), df[df[\"price_type\"] != 0].drop(columns=[\"target\"])\n",
    "Y_train, Y_test = df[df[\"price_type\"] == 0][\"target\"], df[df[\"price_type\"] != 0][\"target\"]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train.iloc[:,:] = scaler.fit_transform(X_train.iloc[:,:])\n",
    "X_test.iloc[:,:] = scaler.transform(X_test.iloc[:,:])\n",
    "\n",
    "# scaler2 = StandardScaler()\n",
    "# Y_train = scaler2.fit_transform(Y_train.values.reshape(-1,1))\n",
    "# Y_test = scaler2.transform(Y_test.values.reshape(-1,1))\n",
    "\n",
    "Y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17676/2200578892.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0miterations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mlearning_rate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.05\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0meval_metric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mR\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[0mtask_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"GPU\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mdevices\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'0:1'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'R' is not defined"
     ]
    }
   ],
   "source": [
    "model = cb.CatBoostRegressor(\n",
    "    iterations=100,\n",
    "    learning_rate=0.05,\n",
    "    eval_metric=R,\n",
    "    task_type=\"GPU\",\n",
    "    devices='0:1'\n",
    ")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aa = model.predict(\n",
    "    X_test\n",
    ")\n",
    "print(deviation_metric(Y_test, aa))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Настин Катбуст\n",
    "class RmseObjective(object):\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "\n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            der1 = targets[index] - approxes[index]\n",
    "            der2 = -1\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "            result.append((der1, der2))\n",
    "        return result\n",
    "\n",
    "class RmseMetric(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return np.sqrt(error / (weight + 1e-38))\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        approx = approxes[0]\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            error_sum += w * (deviation_metric_one_sample(target[i], approx[i])**2)\n",
    "        return error_sum, weight_sum\n",
    "\n",
    "model = cb.CatBoostRegressor(iterations=16, depth=15, learning_rate=0.1, loss_function=RmseObjective(), verbose=True, eval_metric = RmseMetric())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\catboost\\core.py:1913: UserWarning: Failed to import numba for optimizing custom metrics and objectives\n",
      "  _check_train_params(params)\n"
     ]
    },
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4893c360c9b64ee1be4b4e064fd730ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got unsafe target value = 1.63931e+06 at object #576 of dataset learn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 9.5805716\ttotal: 3.66s\tremaining: 55s\n",
      "1:\tlearn: 9.1928775\ttotal: 7.32s\tremaining: 51.3s\n",
      "2:\tlearn: 8.7804832\ttotal: 11s\tremaining: 47.7s\n",
      "3:\tlearn: 8.3017511\ttotal: 14.7s\tremaining: 44.1s\n",
      "4:\tlearn: 7.7753389\ttotal: 18.5s\tremaining: 40.7s\n",
      "5:\tlearn: 7.2815133\ttotal: 22.3s\tremaining: 37.1s\n",
      "6:\tlearn: 6.8509196\ttotal: 26s\tremaining: 33.4s\n",
      "7:\tlearn: 6.5018802\ttotal: 29.8s\tremaining: 29.8s\n",
      "8:\tlearn: 6.2138723\ttotal: 33.6s\tremaining: 26.2s\n",
      "9:\tlearn: 6.0053069\ttotal: 37.5s\tremaining: 22.5s\n",
      "10:\tlearn: 5.8344883\ttotal: 41.5s\tremaining: 18.9s\n",
      "11:\tlearn: 5.7052452\ttotal: 45.4s\tremaining: 15.1s\n",
      "12:\tlearn: 5.5942133\ttotal: 49.4s\tremaining: 11.4s\n",
      "13:\tlearn: 5.5287257\ttotal: 53.2s\tremaining: 7.6s\n",
      "14:\tlearn: 5.4604700\ttotal: 57.1s\tremaining: 3.81s\n",
      "15:\tlearn: 5.4221090\ttotal: 1m 1s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostRegressor at 0x238c8e98310>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    verbose=True,\n",
    "    plot=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "lasso = Lasso(alpha=0.0005, random_state = 1,max_iter=100)\n",
    "\n",
    "ENet = ElasticNet(alpha = 0.0005, l1_ratio=0.9, random_state = 3,max_iter=100)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators = 100,learning_rate=0.05,\n",
    "                                   max_depth = 10, random_state=5)\n",
    "\n",
    "model_rf = RandomForestRegressor(max_depth=17,n_estimators=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.0005, max_iter=100, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+15, tolerance: 8.239e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.91867661972802\n",
      "ElasticNet(alpha=0.0005, l1_ratio=0.9, max_iter=100, random_state=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+15, tolerance: 8.239e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9187240254775295\n",
      "GradientBoostingRegressor(learning_rate=0.05, max_depth=10, random_state=5)\n",
      "2.803620569147034\n",
      "RandomForestRegressor(max_depth=17)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17676/567874878.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mY_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mtr_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdeviation_metric\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mY_test\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtr_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    439\u001B[0m             \u001B[1;31m# parallel_backend contexts set at a higher level,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    440\u001B[0m             \u001B[1;31m# since correctness does not rely on using threads.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 441\u001B[1;33m             trees = Parallel(\n\u001B[0m\u001B[0;32m    442\u001B[0m                 \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    443\u001B[0m                 \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1044\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1045\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    208\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 209\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    182\u001B[0m             \u001B[0mcurr_sample_weight\u001B[0m \u001B[1;33m*=\u001B[0m \u001B[0mcompute_sample_weight\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"balanced\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 184\u001B[1;33m         \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    185\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    186\u001B[0m         \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m   1313\u001B[0m         \"\"\"\n\u001B[0;32m   1314\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1315\u001B[1;33m         super().fit(\n\u001B[0m\u001B[0;32m   1316\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1317\u001B[0m             \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    418\u001B[0m             )\n\u001B[0;32m    419\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 420\u001B[1;33m         \u001B[0mbuilder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    422\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "models = [lasso,ENet,GBoost,model_rf]\n",
    "scores={}\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.fit(X_train.values,Y_train.values)\n",
    "    tr_pred = model.predict(X_test.values)\n",
    "    print(deviation_metric(Y_test.values,tr_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler,StandardScaler,OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error,auc\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=3):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "\n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "\n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as\n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import typing\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "\n",
    "train_dataset = cb.Pool(X_train.values, Y_train)\n",
    "test_dataset = cb.Pool(X_test.values, Y_test)\n",
    "\n",
    "\n",
    "class CatBoostEvalMetricRaifhack(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # the larger metric value the better\n",
    "        return False\n",
    "\n",
    "    def deviation_metric_one_sample(self, y_pred: typing.Union[float, int], y_true: typing.Union[float, int]) -> float:\n",
    "        \"\"\"\n",
    "        Реализация кастомной метрики для хакатона.\n",
    "\n",
    "        :param y_true: float, реальная цена\n",
    "        :param y_pred: float, предсказанная цена\n",
    "        :return: float, значение метрики\n",
    "        \"\"\"\n",
    "        THRESHOLD = 0.15\n",
    "        NEGATIVE_WEIGHT = 1.1\n",
    "        deviation = (y_pred - y_true) / np.maximum(1e-8, y_true)\n",
    "        if np.abs(deviation) <= THRESHOLD:\n",
    "            return 0\n",
    "        elif deviation <= - 4 * THRESHOLD:\n",
    "            return 9 * NEGATIVE_WEIGHT\n",
    "        elif deviation < -THRESHOLD:\n",
    "            return NEGATIVE_WEIGHT * ((deviation / THRESHOLD) + 1) ** 2\n",
    "        elif deviation < 4 * THRESHOLD:\n",
    "            return ((deviation / THRESHOLD) - 1) ** 2\n",
    "        else:\n",
    "            return 9\n",
    "\n",
    "    def evaluate(self, y_pred, y_true, weight):\n",
    "        y_pred = y_pred[0]\n",
    "        return np.array([self.deviation_metric_one_sample(y_pred[n], y_true[n]) for n in range(len(y_pred))]).mean(), 0\n",
    "\n",
    "\n",
    "model = cb.CatBoostRegressor(\n",
    "    iterations=100,\n",
    "    learning_rate=0.5,\n",
    "    eval_metric=CatBoostEvalMetricRaifhack(),\n",
    "    # task_type=\"GPU\",\n",
    "    # devices='0:1'\n",
    ")\n",
    "# model.fit(\n",
    "#     X_train,\n",
    "#     Y_train,\n",
    "#     verbose=False,\n",
    "#     plot=True\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (model_rf, model),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "\n",
    "stacked_averaged_models.fit(X_train.values, Y_train.values)\n",
    "\n",
    "stacked_train_pred = stacked_averaged_models.predict(X_test.values)\n",
    "print(deviation_metric(Y_test.values, stacked_train_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}